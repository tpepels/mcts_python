{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=2 t_r=1.00 l_t=0.00 *** d=3 t_r=0.97 l_t=0.03 *** d=4 t_r=0.76 l_t=0.21 *** d=5 t_r=0.20 l_t=0.56 *** \n",
      "1 Max Player          : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(2, 2)\u001b[0m\n",
      "Best Value            : \u001b[34m\u001b[1m3.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m61\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m142\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m3,405\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m18,529\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m97,547\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m1,591\u001b[0m\n",
      "Null Moves Cutoff     : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m0.796\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Search Timed Out      : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.026\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.213\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.557\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m812\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m17,309\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m3,622\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m16,498\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m65,536\u001b[0m\n",
      "Player AlphaBetaPlayer(player=1, max_depth=25, max_time=1, evaluate=evaluate_tictactoe, use_null_moves=True, use_quiescence=False, use_transpositions=True, tt_size=65536) chosen action: (2, 2). Current game state: \n",
      "    |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   | X |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "\n",
      "hash: 15304994543579972657\n",
      "d=2 t_r=1.00 l_t=0.00 *** d=3 t_r=0.98 l_t=0.02 *** d=4 t_r=0.82 l_t=0.16 *** d=5 t_r=-0.17 l_t=0.99 *** \n",
      "2 Max Player          : \u001b[32m\u001b[1m2\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(0, 0)\u001b[0m\n",
      "Best Value            : \u001b[36m\u001b[1mDRAW\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m60\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m227\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m7,707\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m25,636\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m263,435\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m4,380\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m1.174\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Search Timed Out      : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.018\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.163\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.993\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m3,531\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m26,023\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m5,277\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m24,739\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m65,536\u001b[0m\n",
      "Player AlphaBetaPlayer(player=2, max_depth=25, max_time=1, evaluate=evaluate_tictactoe, use_null_moves=False, use_quiescence=False, use_transpositions=True, tt_size=65536) chosen action: (0, 0). Current game state: \n",
      "  O |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   | X |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "\n",
      "hash: 2517169336099885869\n",
      "d=2 t_r=1.00 l_t=0.00 *** d=3 t_r=0.92 l_t=0.08 *** d=4 t_r=0.72 l_t=0.20 *** d=5 t_r=0.01 l_t=0.71 *** \n",
      "1 Max Player          : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(5, 2)\u001b[0m\n",
      "Best Value            : \u001b[34m\u001b[1m17.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m60\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m123\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m2,725\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m29,079\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m61,528\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m1,032\u001b[0m\n",
      "Null Moves Cutoff     : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m0.990\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Search Timed Out      : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.079\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.199\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.712\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m593\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m27,411\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m3,139\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m43,470\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m65,536\u001b[0m\n",
      "Player AlphaBetaPlayer(player=1, max_depth=25, max_time=1, evaluate=evaluate_tictactoe, use_null_moves=True, use_quiescence=False, use_transpositions=True, tt_size=65536) chosen action: (5, 2). Current game state: \n",
      "  O |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   | X |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   | X |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "\n",
      "hash: 13749463248125006415\n",
      "d=2 t_r=1.00 l_t=0.00 *** d=3 t_r=0.98 l_t=0.02 *** d=4 t_r=0.28 l_t=0.70 *** \n",
      "2 Max Player          : \u001b[32m\u001b[1m2\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(0, 2)\u001b[0m\n",
      "Best Value            : \u001b[34m\u001b[1m14.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m3\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m3\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m59\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m59\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m657\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m21,715\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m38,293\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m647\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m0.720\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Search Timed Out      : \u001b[33m\u001b[1mFalse\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.015\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.705\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m244\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m21,237\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m1,543\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m45,558\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m65,536\u001b[0m\n",
      "Player AlphaBetaPlayer(player=2, max_depth=25, max_time=1, evaluate=evaluate_tictactoe, use_null_moves=False, use_quiescence=False, use_transpositions=True, tt_size=65536) chosen action: (0, 2). Current game state: \n",
      "  O |   | O |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   | X |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   | X |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "\n",
      "hash: 17079887998088091727\n",
      "d=2 t_r=1.00 l_t=0.00 *** d=3 t_r=1.00 l_t=0.00 *** d=4 t_r=1.00 l_t=0.00 *** d=5 t_r=-0.34 l_t=1.34 *** \n",
      "1 Max Player          : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(4, 3)\u001b[0m\n",
      "Best Value            : \u001b[34m\u001b[1m3.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m57\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m3\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m4,337\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m38,184\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m107,326\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m1,881\u001b[0m\n",
      "Null Moves Cutoff     : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m1.338\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Search Timed Out      : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.000\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.000\u001b[0m\n",
      "                        \u001b[34m\u001b[1m1.337\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m188\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m36,845\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m12,914\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m5,083\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m65,536\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m65,536\u001b[0m\n",
      "Player AlphaBetaPlayer(player=1, max_depth=25, max_time=1, evaluate=evaluate_tictactoe, use_null_moves=True, use_quiescence=False, use_transpositions=True, tt_size=65536) chosen action: (4, 3). Current game state: \n",
      "  O |   | O |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   | X |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   | X |   |   |   |   \n",
      "-------------------------------\n",
      "   |   | X |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "-------------------------------\n",
      "   |   |   |   |   |   |   |   \n",
      "\n",
      "hash: 8322039092803480829\n",
      "d=2 t_r=1.00 l_t=0.00 *** d=3 t_r=0.99 l_t=0.01 *** "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m p1_params \u001b[39m=\u001b[39m AIParams(ai_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39malphabeta\u001b[39m\u001b[39m'\u001b[39m, eval_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mevaluate_tictactoe\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m                      ai_params\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmax_time\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdebug\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39muse_null_moves\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m})\n\u001b[1;32m      5\u001b[0m p2_params \u001b[39m=\u001b[39m AIParams(ai_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39malphabeta\u001b[39m\u001b[39m'\u001b[39m, eval_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mevaluate_tictactoe\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m                      ai_params\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmax_time\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdebug\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m})\n\u001b[0;32m----> 8\u001b[0m run_game(game_key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtictactoe\u001b[39;49m\u001b[39m'\u001b[39;49m, game_params\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mboard_size\u001b[39;49m\u001b[39m\"\u001b[39;49m : \u001b[39m8\u001b[39;49m}, p1_params\u001b[39m=\u001b[39;49mp1_params, p2_params\u001b[39m=\u001b[39;49mp2_params)\n",
      "File \u001b[0;32m~/github/mcts_python/run_games.py:192\u001b[0m, in \u001b[0;36mrun_game\u001b[0;34m(game_key, game_params, p1_params, p2_params)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGame Over. Draw\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    191\u001b[0m game, p1, p2 \u001b[39m=\u001b[39m init_game_and_players(game_key, game_params, p1_params, p2_params)\n\u001b[0;32m--> 192\u001b[0m reward \u001b[39m=\u001b[39m play_game_until_terminal(game, p1, p2, callback\u001b[39m=\u001b[39;49mcallback)\n\u001b[1;32m    194\u001b[0m p1\u001b[39m.\u001b[39mprint_cumulative_statistics()\n\u001b[1;32m    195\u001b[0m p2\u001b[39m.\u001b[39mprint_cumulative_statistics()\n",
      "File \u001b[0;32m~/github/mcts_python/run_games.py:156\u001b[0m, in \u001b[0;36mplay_game_until_terminal\u001b[0;34m(game, player1, player2, callback)\u001b[0m\n\u001b[1;32m    153\u001b[0m current_player: AIPlayer \u001b[39m=\u001b[39m player1\n\u001b[1;32m    154\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m game\u001b[39m.\u001b[39mis_terminal():\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Get the best action for the current player\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     action, _ \u001b[39m=\u001b[39m current_player\u001b[39m.\u001b[39;49mbest_action(game)\n\u001b[1;32m    158\u001b[0m     \u001b[39m# Apply the action to get the new game state\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     game \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mapply_action(action)\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:275\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m interrupted \u001b[39mor\u001b[39;00m ((time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time) \u001b[39m+\u001b[39m (search_times[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_time):\n\u001b[1;32m    273\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Stop searching if the time limit has been exceeded or if there's not enough time to do another search\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m v, best_move \u001b[39m=\u001b[39m value(\n\u001b[1;32m    276\u001b[0m     state,\n\u001b[1;32m    277\u001b[0m     \u001b[39m-\u001b[39;49m\u001b[39mfloat\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39minf\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    278\u001b[0m     \u001b[39mfloat\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39minf\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    279\u001b[0m     depth,\n\u001b[1;32m    280\u001b[0m     max_d\u001b[39m=\u001b[39;49mdepth,\n\u001b[1;32m    281\u001b[0m     allow_null_move\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    282\u001b[0m     root\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m max_depth_reached \u001b[39m=\u001b[39m depth\n\u001b[1;32m    286\u001b[0m \u001b[39m# keep track of the time spent\u001b[39;00m\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:189\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m actions:\n\u001b[1;32m    188\u001b[0m     new_state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_action(move)\n\u001b[0;32m--> 189\u001b[0m     min_v, _ \u001b[39m=\u001b[39m value(\n\u001b[1;32m    190\u001b[0m         new_state,\n\u001b[1;32m    191\u001b[0m         alpha,\n\u001b[1;32m    192\u001b[0m         beta,\n\u001b[1;32m    193\u001b[0m         depth \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    194\u001b[0m         max_d\u001b[39m=\u001b[39;49mmax_d,\n\u001b[1;32m    195\u001b[0m         root\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    196\u001b[0m         allow_null_move\u001b[39m=\u001b[39;49mallow_null_move,\n\u001b[1;32m    197\u001b[0m     )\n\u001b[1;32m    198\u001b[0m     \u001b[39mif\u001b[39;00m min_v \u001b[39m>\u001b[39m v:\n\u001b[1;32m    199\u001b[0m         v \u001b[39m=\u001b[39m min_v\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:228\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m actions:\n\u001b[1;32m    227\u001b[0m     new_state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_action(move)\n\u001b[0;32m--> 228\u001b[0m     max_v, _ \u001b[39m=\u001b[39m value(\n\u001b[1;32m    229\u001b[0m         new_state,\n\u001b[1;32m    230\u001b[0m         alpha,\n\u001b[1;32m    231\u001b[0m         beta,\n\u001b[1;32m    232\u001b[0m         depth \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    233\u001b[0m         max_d\u001b[39m=\u001b[39;49mmax_d,\n\u001b[1;32m    234\u001b[0m         root\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    235\u001b[0m         allow_null_move\u001b[39m=\u001b[39;49mallow_null_move,\n\u001b[1;32m    236\u001b[0m     )\n\u001b[1;32m    238\u001b[0m     \u001b[39mif\u001b[39;00m max_v \u001b[39m<\u001b[39m v:\n\u001b[1;32m    239\u001b[0m         cutoffs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:189\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m actions:\n\u001b[1;32m    188\u001b[0m     new_state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_action(move)\n\u001b[0;32m--> 189\u001b[0m     min_v, _ \u001b[39m=\u001b[39m value(\n\u001b[1;32m    190\u001b[0m         new_state,\n\u001b[1;32m    191\u001b[0m         alpha,\n\u001b[1;32m    192\u001b[0m         beta,\n\u001b[1;32m    193\u001b[0m         depth \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    194\u001b[0m         max_d\u001b[39m=\u001b[39;49mmax_d,\n\u001b[1;32m    195\u001b[0m         root\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    196\u001b[0m         allow_null_move\u001b[39m=\u001b[39;49mallow_null_move,\n\u001b[1;32m    197\u001b[0m     )\n\u001b[1;32m    198\u001b[0m     \u001b[39mif\u001b[39;00m min_v \u001b[39m>\u001b[39m v:\n\u001b[1;32m    199\u001b[0m         v \u001b[39m=\u001b[39m min_v\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:123\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m depth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m interrupted:\n\u001b[1;32m    122\u001b[0m     evaluated \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 123\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(state, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplayer)\n\u001b[1;32m    124\u001b[0m     \u001b[39m# If not a null-move result\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[39mif\u001b[39;00m allow_null_move:\n",
      "File \u001b[0;32m~/github/mcts_python/games/tictactoe.py:200\u001b[0m, in \u001b[0;36mevaluate_tictactoe\u001b[0;34m(state, player, m_opp_disc, m_score)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mfor\u001b[39;00m marks \u001b[39min\u001b[39;00m lines:\n\u001b[1;32m    199\u001b[0m     score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m calculate_score(marks, m_score)\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mif\u001b[39;00m potential_win(marks):\n\u001b[1;32m    201\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m10000\u001b[39m \u001b[39mif\u001b[39;00m state\u001b[39m.\u001b[39mplayer \u001b[39m==\u001b[39m player \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m10000\u001b[39m\n\u001b[1;32m    203\u001b[0m \u001b[39m# Discount score if it is the opponent's turn\u001b[39;00m\n",
      "File \u001b[0;32m~/github/mcts_python/games/tictactoe.py:180\u001b[0m, in \u001b[0;36mevaluate_tictactoe.<locals>.potential_win\u001b[0;34m(marks)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpotential_win\u001b[39m(marks):\n\u001b[0;32m--> 180\u001b[0m     \u001b[39mreturn\u001b[39;00m marks\u001b[39m.\u001b[39mcount(player \u001b[39mif\u001b[39;00m state\u001b[39m.\u001b[39mplayer \u001b[39m==\u001b[39m player \u001b[39melse\u001b[39;00m opponent) \u001b[39m==\u001b[39m size \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m marks\u001b[39m.\u001b[39mcount(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_tictactoe', \n",
    "                     ai_params={\"max_time\": 1, \"debug\": True, \"use_null_moves\": True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_tictactoe', \n",
    "                     ai_params={\"max_time\": 1, \"debug\": True})\n",
    "# TODO Als variant op tictactoe heb je een game nu waarin je arbitrair lange rijen kan maken, je moet de evaluatiefunct hierop nog even aanpassen\n",
    "run_game(game_key='tictactoe', game_params={\"board_size\" : 8}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_breakthrough_lorenz', \n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_null_moves\":False, \"use_quiescence\":True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_breakthrough_lorenz', \n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_null_moves\":False})\n",
    "\n",
    "run_game(game_key='breakthrough', game_params={}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_kalah', \n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_kalah', \n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "\n",
    "run_game(game_key='kalah', game_params={}, p1_params=p1_params, p2_params=p2_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_amazons', \n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_amazons',\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "\n",
    "run_game(game_key='amazons', game_params={\"board_size\": 8}, p1_params=p1_params, p2_params=p2_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
