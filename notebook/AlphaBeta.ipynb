{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_tictactoe', max_player=1,\n",
    "                     ai_params={\"max_time\": 1, \"debug\": True, \"use_tt\": False})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_tictactoe', max_player=2,\n",
    "                     ai_params={\"max_time\": 1, \"debug\": True})\n",
    "run_game(game_key='tictactoe', game_params={\"board_size\" : 4}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=2 t_r=16.00 l_t=0.00 *** d=3 t_r=15.66 l_t=0.34 *** d=4 t_r=13.58 l_t=2.08 *** d=5 t_r=3.78 l_t=9.79 *** \n",
      "1 Max Player          : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(4, 6)\u001b[0m\n",
      "Best Value            : \u001b[34m\u001b[1m-3.900\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m78\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m892\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m18,546\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m60,882\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m633,952\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m8,115\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mFalse\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m12.22 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m12.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.34 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m2.08 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m9.79 seconds\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m892\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m7,223\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m892\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m7,223\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m65,536\u001b[0m\n",
      "Player AlphaBetaPlayer(player=1, max_depth=25, max_time=16, evaluate=evaluate_n_in_a_row, use_null_moves=False, use_quiescence=False, use_transpositions=True, tt_size=65536) chosen action: (4, 6). Current game state: \n",
      "    |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   | X |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "\n",
      "hash: 14345139071511466351\n",
      "d=2 t_r=6.00 l_t=0.00 *** d=3 t_r=5.62 l_t=0.38 *** d=4 t_r=4.12 l_t=1.50 *** d=5 t_r=0.64 l_t=3.48 *** \n",
      "2 Max Player          : \u001b[32m\u001b[1m2\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(4, 4)\u001b[0m\n",
      "Best Value            : \u001b[34m\u001b[1m0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m77\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m203\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m4,321\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m28,608\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m116,923\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m1,510\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m5.36 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m5.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.38 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m1.50 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m3.48 seconds\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m203\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m1,307\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m203\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m1,307\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m65,536\u001b[0m\n",
      "Player AlphaBetaPlayer(player=2, max_depth=25, max_time=6, evaluate=evaluate_n_in_a_row, use_null_moves=False, use_quiescence=False, use_transpositions=True, tt_size=65536) chosen action: (4, 4). Current game state: \n",
      "    |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   | O |   | X |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "-----------------------------------\n",
      "   |   |   |   |   |   |   |   |   \n",
      "\n",
      "hash: 1583310399556578930\n",
      "d=2 t_r=16.00 l_t=0.00 *** d=3 t_r=15.89 l_t=0.11 *** "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m p2_params \u001b[39m=\u001b[39m AIParams(ai_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39malphabeta\u001b[39m\u001b[39m'\u001b[39m, eval_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mevaluate_n_in_a_row\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                      max_player\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, ai_params\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmax_time\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m6\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdebug\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m})\n\u001b[1;32m      7\u001b[0m \u001b[39m# An n-in-a-row game\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m run_game(game_key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtictactoe\u001b[39;49m\u001b[39m'\u001b[39;49m, game_params\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mboard_size\u001b[39;49m\u001b[39m\"\u001b[39;49m : \u001b[39m9\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrow_length\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m6\u001b[39;49m}, \n\u001b[1;32m      9\u001b[0m          p1_params\u001b[39m=\u001b[39;49mp1_params, p2_params\u001b[39m=\u001b[39;49mp2_params)\n",
      "File \u001b[0;32m~/github/mcts_python/run_games.py:204\u001b[0m, in \u001b[0;36mrun_game\u001b[0;34m(game_key, game_params, p1_params, p2_params)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGame Over. Draw\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    203\u001b[0m game, p1, p2 \u001b[39m=\u001b[39m init_game_and_players(game_key, game_params, p1_params, p2_params)\n\u001b[0;32m--> 204\u001b[0m reward \u001b[39m=\u001b[39m play_game_until_terminal(game, p1, p2, callback\u001b[39m=\u001b[39;49mcallback)\n\u001b[1;32m    206\u001b[0m p1\u001b[39m.\u001b[39mprint_cumulative_statistics()\n\u001b[1;32m    207\u001b[0m p2\u001b[39m.\u001b[39mprint_cumulative_statistics()\n",
      "File \u001b[0;32m~/github/mcts_python/run_games.py:168\u001b[0m, in \u001b[0;36mplay_game_until_terminal\u001b[0;34m(game, player1, player2, callback)\u001b[0m\n\u001b[1;32m    165\u001b[0m current_player: AIPlayer \u001b[39m=\u001b[39m player1\n\u001b[1;32m    166\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m game\u001b[39m.\u001b[39mis_terminal():\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Get the best action for the current player\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     action, _ \u001b[39m=\u001b[39m current_player\u001b[39m.\u001b[39;49mbest_action(game)\n\u001b[1;32m    170\u001b[0m     \u001b[39m# Apply the action to get the new game state\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     game \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mapply_action(action)\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:258\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mif\u001b[39;00m interrupted \u001b[39mor\u001b[39;00m ((time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time) \u001b[39m+\u001b[39m (search_times[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_time):\n\u001b[1;32m    256\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Stop searching if the time limit has been exceeded or if there's not enough time to do another search\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m v, best_move \u001b[39m=\u001b[39m value(\n\u001b[1;32m    259\u001b[0m     state,\n\u001b[1;32m    260\u001b[0m     \u001b[39m-\u001b[39;49m\u001b[39mfloat\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39minf\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    261\u001b[0m     \u001b[39mfloat\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39minf\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    262\u001b[0m     depth,\n\u001b[1;32m    263\u001b[0m     max_d\u001b[39m=\u001b[39;49mdepth,\n\u001b[1;32m    264\u001b[0m     allow_null_move\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    265\u001b[0m     root\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    266\u001b[0m )\n\u001b[1;32m    267\u001b[0m max_depth_reached \u001b[39m=\u001b[39m depth\n\u001b[1;32m    269\u001b[0m \u001b[39m# keep track of the time spent\u001b[39;00m\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:171\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m actions:\n\u001b[1;32m    170\u001b[0m     new_state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_action(move)\n\u001b[0;32m--> 171\u001b[0m     min_v, _ \u001b[39m=\u001b[39m value(\n\u001b[1;32m    172\u001b[0m         new_state,\n\u001b[1;32m    173\u001b[0m         alpha,\n\u001b[1;32m    174\u001b[0m         beta,\n\u001b[1;32m    175\u001b[0m         depth \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    176\u001b[0m         max_d\u001b[39m=\u001b[39;49mmax_d,\n\u001b[1;32m    177\u001b[0m         root\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m         allow_null_move\u001b[39m=\u001b[39;49mallow_null_move,\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m     \u001b[39mif\u001b[39;00m min_v \u001b[39m>\u001b[39m v:\n\u001b[1;32m    181\u001b[0m         v \u001b[39m=\u001b[39m min_v\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:210\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m actions:\n\u001b[1;32m    209\u001b[0m     new_state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_action(move)\n\u001b[0;32m--> 210\u001b[0m     max_v, _ \u001b[39m=\u001b[39m value(\n\u001b[1;32m    211\u001b[0m         new_state,\n\u001b[1;32m    212\u001b[0m         alpha,\n\u001b[1;32m    213\u001b[0m         beta,\n\u001b[1;32m    214\u001b[0m         depth \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    215\u001b[0m         max_d\u001b[39m=\u001b[39;49mmax_d,\n\u001b[1;32m    216\u001b[0m         root\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    217\u001b[0m         allow_null_move\u001b[39m=\u001b[39;49mallow_null_move,\n\u001b[1;32m    218\u001b[0m     )\n\u001b[1;32m    220\u001b[0m     \u001b[39mif\u001b[39;00m max_v \u001b[39m<\u001b[39m v:\n\u001b[1;32m    221\u001b[0m         cutoffs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:171\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m actions:\n\u001b[1;32m    170\u001b[0m     new_state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_action(move)\n\u001b[0;32m--> 171\u001b[0m     min_v, _ \u001b[39m=\u001b[39m value(\n\u001b[1;32m    172\u001b[0m         new_state,\n\u001b[1;32m    173\u001b[0m         alpha,\n\u001b[1;32m    174\u001b[0m         beta,\n\u001b[1;32m    175\u001b[0m         depth \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    176\u001b[0m         max_d\u001b[39m=\u001b[39;49mmax_d,\n\u001b[1;32m    177\u001b[0m         root\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m         allow_null_move\u001b[39m=\u001b[39;49mallow_null_move,\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m     \u001b[39mif\u001b[39;00m min_v \u001b[39m>\u001b[39m v:\n\u001b[1;32m    181\u001b[0m         v \u001b[39m=\u001b[39m min_v\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:115\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m depth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m interrupted:\n\u001b[1;32m    114\u001b[0m     evaluated \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 115\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(state, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplayer)\n\u001b[1;32m    116\u001b[0m     \u001b[39mreturn\u001b[39;00m v, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    118\u001b[0m is_max_player \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mplayer \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplayer\n",
      "File \u001b[0;32m~/github/mcts_python/games/tictactoe.py:293\u001b[0m, in \u001b[0;36mevaluate_n_in_a_row\u001b[0;34m(state, player, m_weight, m_e_weight, m_opp_disc, m_win)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(row_length \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, size):\n\u001b[1;32m    292\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(size \u001b[39m-\u001b[39m row_length \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m         lines\u001b[39m.\u001b[39mappend([board[i \u001b[39m-\u001b[39m k][j \u001b[39m+\u001b[39m k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(row_length)])\n\u001b[1;32m    295\u001b[0m potential_wins \u001b[39m=\u001b[39m {player: \u001b[39m0\u001b[39m, opponent: \u001b[39m0\u001b[39m}\n\u001b[1;32m    297\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_n_in_a_row',\n",
    "                     max_player=1, ai_params={\"max_time\": 16, \"debug\": True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_n_in_a_row',\n",
    "                     max_player=2, ai_params={\"max_time\": 6, \"debug\": True})\n",
    "# An n-in-a-row game\n",
    "run_game(game_key='tictactoe', game_params={\"board_size\" : 9, \"row_length\": 6}, \n",
    "         p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_breakthrough_lorenz', max_player=1,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_tt\": False, \"use_null_moves\":True, \"use_quiescence\":True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_breakthrough_lorenz', max_player=2,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_null_moves\":False})\n",
    "\n",
    "run_game(game_key='breakthrough', game_params={}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_kalah_enhanced', max_player=1,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_tt\": False, \"use_quiescence\": True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_kalah_enhanced', max_player=2,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "\n",
    "run_game(game_key='kalah', game_params={}, p1_params=p1_params, p2_params=p2_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_amazons', max_player=1,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_tt\": False})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_amazons',max_player=2,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "\n",
    "run_game(game_key='amazons', game_params={\"board_size\": 8}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_blokus', max_player=1,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True,})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_blokus',max_player=2,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "\n",
    "run_game(game_key='blokus', game_params={}, p1_params=p1_params, p2_params=p2_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
