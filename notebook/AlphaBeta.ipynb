{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_tictactoe', max_player=1,\n",
    "                     ai_params={\"max_time\": 1, \"debug\": True, \"use_tt\": False})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_tictactoe', max_player=2,\n",
    "                     ai_params={\"max_time\": 1, \"debug\": True})\n",
    "run_game(game_key='tictactoe', game_params={\"board_size\" : 4}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_n_in_a_row',\n",
    "                     max_player=1, ai_params={\"max_time\": 16, \"debug\": True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_n_in_a_row',\n",
    "                     max_player=2, ai_params={\"max_time\": 6, \"debug\": True})\n",
    "# An n-in-a-row game\n",
    "run_game(game_key='tictactoe', game_params={\"board_size\" : 9, \"row_length\": 6}, \n",
    "         p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.88 l_t=0.12 *** d=4 t_r=8.96 l_t=0.92 *** d=5 t_r=4.21 l_t=4.75 *** \n",
      "1 Max Player          : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(50, 41)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m23\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m2,859\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m8,266\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m34,868\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m262.532\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m1,519\u001b[0m\n",
      "Null Moves Cutoff     : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Quiescence Searches   : \u001b[32m\u001b[1m21\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mFalse\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m5.79 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m5.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.12 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.92 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m4.75 seconds\u001b[0m\n",
      "Player AlphaBetaPlayer(player=1, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=True, use_quiescence=True, use_transpositions=False, tt_size=None) chosen action: (50, 41). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B B B B B B B B\n",
      "3 . . . . . . . .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W . . . . . .\n",
      "7 W W . W W W W W\n",
      "8 W W W W W W W W\n",
      "hash: 9796880788475756187\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.95 l_t=0.05 *** d=4 t_r=9.75 l_t=0.20 *** d=5 t_r=8.94 l_t=0.82 *** d=6 t_r=3.77 l_t=5.17 *** \n",
      "2 Max Player          : \u001b[32m\u001b[1m2\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(10, 17)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m-0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m6\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m25\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m1,153\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m2,542\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m17,932\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m64,240\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m420.445\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m2,621\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mFalse\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m6.23 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m6.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.05 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.20 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.82 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m5.17 seconds\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m1,153\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m1,468\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m1,153\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m1,468\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m262,144\u001b[0m\n",
      "Player AlphaBetaPlayer(player=2, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=False, use_quiescence=False, use_transpositions=True, tt_size=262144) chosen action: (10, 17). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B B . B B B B B\n",
      "3 . B . . . . . .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W . . . . . .\n",
      "7 W W . W W W W W\n",
      "8 W W W W W W W W\n",
      "hash: 6302498806157453782\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.91 l_t=0.09 *** d=4 t_r=9.10 l_t=0.81 *** d=5 t_r=3.52 l_t=5.59 *** \n",
      "1 Max Player          : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(52, 43)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m24\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m2,826\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m9,562\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m43,440\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m274.613\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m1,780\u001b[0m\n",
      "Null Moves Cutoff     : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Quiescence Searches   : \u001b[32m\u001b[1m60\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mFalse\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m6.48 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m6.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.09 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.81 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m5.59 seconds\u001b[0m\n",
      "Player AlphaBetaPlayer(player=1, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=True, use_quiescence=True, use_transpositions=False, tt_size=None) chosen action: (52, 43). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B B . B B B B B\n",
      "3 . B . . . . . .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W . W . . . .\n",
      "7 W W . W . W W W\n",
      "8 W W W W W W W W\n",
      "hash: 2545891166570574379\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.98 l_t=0.02 *** d=4 t_r=9.78 l_t=0.20 *** d=5 t_r=8.84 l_t=0.94 *** d=6 t_r=0.88 l_t=7.96 *** \n",
      "2 Max Player          : \u001b[32m\u001b[1m2\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(9, 18)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m-0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m6\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m26\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m1,336\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m3,804\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m26,134\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m101,732\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m425.959\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m3,883\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m9.12 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m7.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.02 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.20 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.94 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m7.96 seconds\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m1,336\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m2,547\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m1,099\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m4,015\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m262,144\u001b[0m\n",
      "Player AlphaBetaPlayer(player=2, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=False, use_quiescence=False, use_transpositions=True, tt_size=262144) chosen action: (9, 18). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B . . B B B B B\n",
      "3 . B B . . . . .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W . W . . . .\n",
      "7 W W . W . W W W\n",
      "8 W W W W W W W W\n",
      "hash: 9026550707182536754\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.92 l_t=0.08 *** d=4 t_r=8.97 l_t=0.95 *** d=5 t_r=2.83 l_t=6.14 *** \n",
      "1 Max Player          : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(54, 45)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m27\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m2,739\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m10,007\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m45,715\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m236.436\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m1,696\u001b[0m\n",
      "Null Moves Cutoff     : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Quiescence Searches   : \u001b[32m\u001b[1m475\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mFalse\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m7.17 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m6.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.08 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.95 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m6.14 seconds\u001b[0m\n",
      "Player AlphaBetaPlayer(player=1, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=True, use_quiescence=True, use_transpositions=False, tt_size=None) chosen action: (54, 45). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B . . B B B B B\n",
      "3 . B B . . . . .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W . W . W . .\n",
      "7 W W . W . W . W\n",
      "8 W W W W W W W W\n",
      "hash: 1900583164732297878\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.98 l_t=0.02 *** d=4 t_r=9.74 l_t=0.24 *** d=5 t_r=8.27 l_t=1.47 *** d=6 t_r=0.73 l_t=7.53 *** \n",
      "2 Max Player          : \u001b[32m\u001b[1m2\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(11, 19)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m-0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m6\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m28\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m1,192\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m4,103\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m26,270\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m106,150\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m405.933\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m3,761\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m9.27 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m8.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.02 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.24 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m1.47 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m7.53 seconds\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m1,192\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m2,569\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m954\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m6,584\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m262,144\u001b[0m\n",
      "Player AlphaBetaPlayer(player=2, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=False, use_quiescence=False, use_transpositions=True, tt_size=262144) chosen action: (11, 19). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B . . . B B B B\n",
      "3 . B B B . . . .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W . W . W . .\n",
      "7 W W . W . W . W\n",
      "8 W W W W W W W W\n",
      "hash: 10419498771525473647\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.89 l_t=0.11 *** d=4 t_r=8.71 l_t=1.17 *** d=5 t_r=0.90 l_t=7.81 *** \n",
      "1 Max Player          : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(49, 42)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m30\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m3,455\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m13,101\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m63,208\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m233.892\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m2,128\u001b[0m\n",
      "Null Moves Cutoff     : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Quiescence Searches   : \u001b[32m\u001b[1m637\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mFalse\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m9.10 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m7.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.11 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m1.17 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m7.81 seconds\u001b[0m\n",
      "Player AlphaBetaPlayer(player=1, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=True, use_quiescence=True, use_transpositions=False, tt_size=None) chosen action: (49, 42). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B . . . B B B B\n",
      "3 . B B B . . . .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W W W . W . .\n",
      "7 W . . W . W . W\n",
      "8 W W W W W W W W\n",
      "hash: 3114387106827711473\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.98 l_t=0.02 *** d=4 t_r=9.69 l_t=0.29 *** d=5 t_r=8.14 l_t=1.55 *** d=6 t_r=0.76 l_t=7.38 *** \n",
      "2 Max Player          : \u001b[32m\u001b[1m2\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(12, 20)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m-0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m6\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m31\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m1,505\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m3,517\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m26,342\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m115,624\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m398.457\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m3,683\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m9.24 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m8.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.02 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.29 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m1.55 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m7.38 seconds\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m1,505\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m2,178\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m1,229\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m8,762\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m262,144\u001b[0m\n",
      "Player AlphaBetaPlayer(player=2, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=False, use_quiescence=False, use_transpositions=True, tt_size=262144) chosen action: (12, 20). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B . . . . B B B\n",
      "3 . B B B B . . .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W W W . W . .\n",
      "7 W . . W . W . W\n",
      "8 W W W W W W W W\n",
      "hash: 8408849500935120417\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.90 l_t=0.10 *** d=4 t_r=8.66 l_t=1.24 *** d=5 t_r=-0.28 l_t=8.94 *** \n",
      "1 Max Player          : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(51, 44)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m33\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m3,599\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m14,856\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m69,585\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m207.646\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m2,135\u001b[0m\n",
      "Null Moves Cutoff     : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Quiescence Searches   : \u001b[32m\u001b[1m919\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mFalse\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m10.28 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m7.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.10 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m1.24 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m8.94 seconds\u001b[0m\n",
      "Player AlphaBetaPlayer(player=1, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=True, use_quiescence=True, use_transpositions=False, tt_size=None) chosen action: (51, 44). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B . . . . B B B\n",
      "3 . B B B B . . .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W W W W W . .\n",
      "7 W . . . . W . W\n",
      "8 W W W W W W W W\n",
      "hash: 12050408773679878555\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.97 l_t=0.03 *** d=4 t_r=9.63 l_t=0.35 *** d=5 t_r=8.27 l_t=1.36 *** d=6 t_r=0.80 l_t=7.46 *** \n",
      "2 Max Player          : \u001b[32m\u001b[1m2\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(14, 21)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m-0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m6\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m34\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m1,320\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m4,386\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m25,724\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m147,824\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m472.847\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m4,349\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m9.20 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m8.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.03 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.35 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m1.36 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m7.46 seconds\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m1,320\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m3,029\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m1,037\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m11,791\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m262,144\u001b[0m\n",
      "Player AlphaBetaPlayer(player=2, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=False, use_quiescence=False, use_transpositions=True, tt_size=262144) chosen action: (14, 21). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B . . . . B . B\n",
      "3 . B B B B B . .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W W W W W . .\n",
      "7 W . . . . W . W\n",
      "8 W W W W W W W W\n",
      "hash: 17287662268282716164\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.78 l_t=0.22 *** d=4 t_r=6.70 l_t=3.08 *** d=5 t_r=3.27 l_t=3.42 *** \n",
      "1 Max Player          : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(53, 46)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m0.019\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m34\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m1,330\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m9,213\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m28,255\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m123.997\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m834\u001b[0m\n",
      "Null Moves Cutoff     : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Quiescence Searches   : \u001b[32m\u001b[1m1,563\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m6.73 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m7.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.22 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m3.08 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m3.42 seconds\u001b[0m\n",
      "Player AlphaBetaPlayer(player=1, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=True, use_quiescence=True, use_transpositions=False, tt_size=None) chosen action: (53, 46). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B . . . . B . B\n",
      "3 . B B B B B . .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W W W W W W .\n",
      "7 W . . . . . . W\n",
      "8 W W W W W W W W\n",
      "hash: 5237727365676483760\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.97 l_t=0.03 *** d=4 t_r=9.58 l_t=0.39 *** d=5 t_r=8.01 l_t=1.57 *** d=6 t_r=0.72 l_t=7.29 *** \n",
      "2 Max Player          : \u001b[32m\u001b[1m2\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(13, 22)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m-0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m6\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m36\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m1,285\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m4,251\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m25,805\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m154,596\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m458.722\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m4,257\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m9.28 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m8.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.03 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.39 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m1.57 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m7.29 seconds\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m1,285\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m2,972\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m984\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m14,763\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m262,144\u001b[0m\n",
      "Player AlphaBetaPlayer(player=2, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=False, use_quiescence=False, use_transpositions=True, tt_size=262144) chosen action: (13, 22). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B . . . . . . B\n",
      "3 . B B B B B B .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 . W W W W W W .\n",
      "7 W . . . . . . W\n",
      "8 W W W W W W W W\n",
      "hash: 1346651301074164182\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.71 l_t=0.29 *** d=4 t_r=4.64 l_t=5.07 *** \n",
      "1 Max Player          : \u001b[32m\u001b[1m1\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(48, 40)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m0.014\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m4\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m3\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m3\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m37\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m485\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m6,193\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m17,932\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m89.984\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m482\u001b[0m\n",
      "Null Moves Cutoff     : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Quiescence Searches   : \u001b[32m\u001b[1m2,899\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mFalse\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m5.36 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m7.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.29 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m5.07 seconds\u001b[0m\n",
      "Player AlphaBetaPlayer(player=1, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=True, use_quiescence=True, use_transpositions=False, tt_size=None) chosen action: (48, 40). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 B . . . . . . B\n",
      "3 . B B B B B B .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 W W W W W W W .\n",
      "7 . . . . . . . W\n",
      "8 W W W W W W W W\n",
      "hash: 13433381439440190150\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.95 l_t=0.05 *** d=4 t_r=9.37 l_t=0.59 *** d=5 t_r=6.37 l_t=2.99 *** d=6 t_r=0.68 l_t=5.70 *** \n",
      "2 Max Player          : \u001b[32m\u001b[1m2\u001b[0m\n",
      "Best Move             : \u001b[39m\u001b[1m(8, 16)\u001b[0m\n",
      "Best Value            : \u001b[39m\u001b[1m-0.000\u001b[0m\n",
      "Depth                 : \u001b[32m\u001b[1m6\u001b[0m\n",
      "Depth Average         : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Depth Finished        : \u001b[32m\u001b[1m5\u001b[0m\n",
      "Nodes Avg Br Fact     : \u001b[32m\u001b[1m40\u001b[0m\n",
      "Nodes Best Move Order : \u001b[32m\u001b[1m1,558\u001b[0m\n",
      "Nodes Cutoff          : \u001b[32m\u001b[1m4,990\u001b[0m\n",
      "Nodes Evaluated       : \u001b[32m\u001b[1m25,567\u001b[0m\n",
      "Nodes Generated       : \u001b[32m\u001b[1m178,426\u001b[0m\n",
      "Nodes Per Sec         : \u001b[34m\u001b[1m483.347\u001b[0m\n",
      "Nodes Visited         : \u001b[32m\u001b[1m4,507\u001b[0m\n",
      "Search Tim Out        : \u001b[33m\u001b[1mTrue\u001b[0m\n",
      "Search Time           : \u001b[34m\u001b[1m9.32 seconds\u001b[0m\n",
      "Search Time Average   : \u001b[32m\u001b[1m8.00 seconds\u001b[0m\n",
      "Search Times P.D      : \u001b[32m\u001b[1m0.00 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.05 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m0.59 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m2.99 seconds\u001b[0m\n",
      "                        \u001b[34m\u001b[1m5.70 seconds\u001b[0m\n",
      "Tt Cache Hits         : \u001b[32m\u001b[1m1,558\u001b[0m\n",
      "Tt Cache Misses       : \u001b[32m\u001b[1m2,949\u001b[0m\n",
      "Tt Cleanups           : \u001b[32m\u001b[1m0\u001b[0m\n",
      "Tt Collisions         : \u001b[32m\u001b[1m1,422\u001b[0m\n",
      "Tt Entries            : \u001b[32m\u001b[1m17,712\u001b[0m\n",
      "Tt Size               : \u001b[32m\u001b[1m262,144\u001b[0m\n",
      "Player AlphaBetaPlayer(player=2, max_depth=25, max_time=10, evaluate=evaluate_breakthrough_lorenz, use_null_moves=False, use_quiescence=False, use_transpositions=True, tt_size=262144) chosen action: (8, 16). Current game state: \n",
      "   A B C D E F G H\n",
      "1 B B B B B B B B\n",
      "2 . . . . . . . B\n",
      "3 B B B B B B B .\n",
      "4 . . . . . . . .\n",
      "5 . . . . . . . .\n",
      "6 W W W W W W W .\n",
      "7 . . . . . . . W\n",
      "8 W W W W W W W W\n",
      "hash: 11929955127122146368\n",
      "d=2 t_r=10.00 l_t=0.00 *** d=3 t_r=9.69 l_t=0.31 *** "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m p1_params \u001b[39m=\u001b[39m AIParams(ai_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39malphabeta\u001b[39m\u001b[39m'\u001b[39m, eval_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mevaluate_breakthrough_lorenz\u001b[39m\u001b[39m'\u001b[39m, max_player\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m      4\u001b[0m                      ai_params\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmax_time\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m10\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdebug\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39muse_tt\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39muse_null_moves\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39muse_quiescence\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mTrue\u001b[39;00m})\n\u001b[1;32m      5\u001b[0m p2_params \u001b[39m=\u001b[39m AIParams(ai_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39malphabeta\u001b[39m\u001b[39m'\u001b[39m, eval_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mevaluate_breakthrough_lorenz\u001b[39m\u001b[39m'\u001b[39m, max_player\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m      6\u001b[0m                      ai_params\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmax_time\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m10\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdebug\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39muse_null_moves\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mFalse\u001b[39;00m})\n\u001b[0;32m----> 8\u001b[0m run_game(game_key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbreakthrough\u001b[39;49m\u001b[39m'\u001b[39;49m, game_params\u001b[39m=\u001b[39;49m{}, p1_params\u001b[39m=\u001b[39;49mp1_params, p2_params\u001b[39m=\u001b[39;49mp2_params)\n",
      "File \u001b[0;32m~/github/mcts_python/run_games.py:198\u001b[0m, in \u001b[0;36mrun_game\u001b[0;34m(game_key, game_params, p1_params, p2_params)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGame Over. Draw\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    197\u001b[0m game, p1, p2 \u001b[39m=\u001b[39m init_game_and_players(game_key, game_params, p1_params, p2_params)\n\u001b[0;32m--> 198\u001b[0m reward \u001b[39m=\u001b[39m play_game_until_terminal(game, p1, p2, callback\u001b[39m=\u001b[39;49mcallback)\n\u001b[1;32m    200\u001b[0m p1\u001b[39m.\u001b[39mprint_cumulative_statistics()\n\u001b[1;32m    201\u001b[0m p2\u001b[39m.\u001b[39mprint_cumulative_statistics()\n",
      "File \u001b[0;32m~/github/mcts_python/run_games.py:162\u001b[0m, in \u001b[0;36mplay_game_until_terminal\u001b[0;34m(game, player1, player2, callback)\u001b[0m\n\u001b[1;32m    159\u001b[0m current_player: AIPlayer \u001b[39m=\u001b[39m player1\n\u001b[1;32m    160\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m game\u001b[39m.\u001b[39mis_terminal():\n\u001b[1;32m    161\u001b[0m     \u001b[39m# Get the best action for the current player\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m     action, _ \u001b[39m=\u001b[39m current_player\u001b[39m.\u001b[39;49mbest_action(game)\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Apply the action to get the new game state\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     game \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mapply_action(action)\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:253\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mif\u001b[39;00m interrupted \u001b[39mor\u001b[39;00m ((time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time) \u001b[39m+\u001b[39m (search_times[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_time):\n\u001b[1;32m    251\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Stop searching if the time limit has been exceeded or if there's not enough time to do another search\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m v, best_move \u001b[39m=\u001b[39m value(\n\u001b[1;32m    254\u001b[0m     state,\n\u001b[1;32m    255\u001b[0m     \u001b[39m-\u001b[39;49m\u001b[39mfloat\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39minf\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    256\u001b[0m     \u001b[39mfloat\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39minf\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    257\u001b[0m     depth,\n\u001b[1;32m    258\u001b[0m     max_d\u001b[39m=\u001b[39;49mdepth,\n\u001b[1;32m    259\u001b[0m     allow_null_move\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    260\u001b[0m     root\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    261\u001b[0m )\n\u001b[1;32m    262\u001b[0m max_depth_reached \u001b[39m=\u001b[39m depth\n\u001b[1;32m    264\u001b[0m \u001b[39m# keep track of the time spent\u001b[39;00m\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:167\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m actions:\n\u001b[1;32m    166\u001b[0m     new_state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_action(move)\n\u001b[0;32m--> 167\u001b[0m     min_v, _ \u001b[39m=\u001b[39m value(\n\u001b[1;32m    168\u001b[0m         new_state,\n\u001b[1;32m    169\u001b[0m         alpha,\n\u001b[1;32m    170\u001b[0m         beta,\n\u001b[1;32m    171\u001b[0m         depth \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    172\u001b[0m         max_d\u001b[39m=\u001b[39;49mmax_d,\n\u001b[1;32m    173\u001b[0m         root\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m         allow_null_move\u001b[39m=\u001b[39;49mallow_null_move,\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m     \u001b[39mif\u001b[39;00m min_v \u001b[39m>\u001b[39m v:\n\u001b[1;32m    177\u001b[0m         v \u001b[39m=\u001b[39m min_v\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:206\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m actions:\n\u001b[1;32m    205\u001b[0m     new_state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_action(move)\n\u001b[0;32m--> 206\u001b[0m     max_v, _ \u001b[39m=\u001b[39m value(\n\u001b[1;32m    207\u001b[0m         new_state,\n\u001b[1;32m    208\u001b[0m         alpha,\n\u001b[1;32m    209\u001b[0m         beta,\n\u001b[1;32m    210\u001b[0m         depth \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    211\u001b[0m         max_d\u001b[39m=\u001b[39;49mmax_d,\n\u001b[1;32m    212\u001b[0m         root\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    213\u001b[0m         allow_null_move\u001b[39m=\u001b[39;49mallow_null_move,\n\u001b[1;32m    214\u001b[0m     )\n\u001b[1;32m    216\u001b[0m     \u001b[39mif\u001b[39;00m max_v \u001b[39m<\u001b[39m v:\n\u001b[1;32m    217\u001b[0m         cutoffs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:167\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m actions:\n\u001b[1;32m    166\u001b[0m     new_state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_action(move)\n\u001b[0;32m--> 167\u001b[0m     min_v, _ \u001b[39m=\u001b[39m value(\n\u001b[1;32m    168\u001b[0m         new_state,\n\u001b[1;32m    169\u001b[0m         alpha,\n\u001b[1;32m    170\u001b[0m         beta,\n\u001b[1;32m    171\u001b[0m         depth \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    172\u001b[0m         max_d\u001b[39m=\u001b[39;49mmax_d,\n\u001b[1;32m    173\u001b[0m         root\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m         allow_null_move\u001b[39m=\u001b[39;49mallow_null_move,\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m     \u001b[39mif\u001b[39;00m min_v \u001b[39m>\u001b[39m v:\n\u001b[1;32m    177\u001b[0m         v \u001b[39m=\u001b[39m min_v\n",
      "File \u001b[0;32m~/github/mcts_python/ai/alpha_beta.py:113\u001b[0m, in \u001b[0;36mAlphaBetaPlayer.best_action.<locals>.value\u001b[0;34m(state, alpha, beta, depth, max_d, allow_null_move, root)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m depth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m interrupted:\n\u001b[1;32m    112\u001b[0m     evaluated \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 113\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(state, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplayer)\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m v, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m is_max_player \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mplayer \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplayer\n",
      "File \u001b[0;32m~/github/mcts_python/games/breakthrough.py:424\u001b[0m, in \u001b[0;36mevaluate_breakthrough_lorenz\u001b[0;34m(state, player, m_lorenz, m_mobility, m_blocked, m_safe, m_endgame, m_cap, m_cap_move, m_opp_disc, a, norm)\u001b[0m\n\u001b[1;32m    421\u001b[0m board_values \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m multiplier \u001b[39m*\u001b[39m piece_value\n\u001b[1;32m    423\u001b[0m \u001b[39mif\u001b[39;00m m_mobility \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m m_blocked \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 424\u001b[0m     mob_val \u001b[39m=\u001b[39m piece_mobility(position, piece, state\u001b[39m.\u001b[39;49mboard)\n\u001b[1;32m    425\u001b[0m     mobility_values \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m multiplier \u001b[39m*\u001b[39m mob_val\n\u001b[1;32m    426\u001b[0m     \u001b[39mif\u001b[39;00m mob_val \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:  \u001b[39m# Keep track of the number of blocked pieces\u001b[39;00m\n",
      "File \u001b[0;32m~/github/mcts_python/games/breakthrough.py:460\u001b[0m, in \u001b[0;36mpiece_mobility\u001b[0;34m(position, player, board)\u001b[0m\n\u001b[1;32m    456\u001b[0m BL_DIR \u001b[39m=\u001b[39m ((\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), (\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), (\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m    457\u001b[0m WH_DIR \u001b[39m=\u001b[39m ((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m--> 460\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpiece_mobility\u001b[39m(position, player, board):\n\u001b[1;32m    461\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[39m    Calculates the mobility of a piece at the given position.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[39m    :return: The mobility value of the piece.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     row, col \u001b[39m=\u001b[39m \u001b[39mdivmod\u001b[39m(position, \u001b[39m8\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_breakthrough_lorenz', max_player=1,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_tt\": False, \"use_null_moves\":True, \"use_quiescence\":True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_breakthrough_lorenz', max_player=2,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_null_moves\":False})\n",
    "\n",
    "run_game(game_key='breakthrough', game_params={}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_kalah_enhanced', max_player=1,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_tt\": False, \"use_quiescence\": True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_kalah_enhanced', max_player=2,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "\n",
    "run_game(game_key='kalah', game_params={}, p1_params=p1_params, p2_params=p2_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_amazons', max_player=1,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_tt\": False})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_amazons',max_player=2,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "\n",
    "run_game(game_key='amazons', game_params={\"board_size\": 8}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_blokus', max_player=1,\n",
    "                     ai_params={\"max_time\": 15, \"debug\": True, \"use_null_moves\": True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_blokus',max_player=2,\n",
    "                     ai_params={\"max_time\": 15, \"debug\": True})\n",
    "\n",
    "run_game(game_key='blokus', game_params={}, p1_params=p1_params, p2_params=p2_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
