{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='mcts', eval_key='evaluate_tictactoe', max_player=1,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "p2_params = AIParams(ai_key='mcts', eval_key='evaluate_tictactoe', max_player=2,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "run_game(game_key='tictactoe', game_params={\"board_size\" : 3}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import init_game_and_players\n",
    "from games.gamestate import win, loss\n",
    "from run_games import AIParams\n",
    "\n",
    "\n",
    "def callback(player, action, game, time):\n",
    "    print(f\"{player} -> mv.: {action}.\\n{game.visualize()}\")\n",
    "    if game.is_terminal():\n",
    "        if game.get_reward(1) == win:\n",
    "            print(\"Game Over. Winner: P1\")\n",
    "        elif game.get_reward(1) == loss:\n",
    "            print(\"Game Over. Winner: P2\")\n",
    "        else:\n",
    "            print(\"Game Over. Draw\")\n",
    "\n",
    "game_key = \"tictactoe\"\n",
    "game_params = {\"board_size\": 3}\n",
    "p1_params = AIParams(\n",
    "    ai_key=\"mcts\",\n",
    "    eval_key=\"evaluate_tictactoe\",\n",
    "    max_player=1,\n",
    "    ai_params={\"num_simulations\": 100, \"debug\": False},\n",
    ")\n",
    "p2_params = AIParams(\n",
    "    ai_key=\"mcts\",\n",
    "    eval_key=\"evaluate_tictactoe\",\n",
    "    max_player=2,\n",
    "    ai_params={\"num_simulations\": 100, \"debug\": False},\n",
    ")\n",
    "game, player1, player2 = init_game_and_players(game_key, game_params, p1_params, p2_params)\n",
    "current_player = player1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MCTS player=1, evaluate=<cyfunction evaluate_tictactoe at 0x11c178450>, transposition_table_size=65536, num_simulations=100, max_time=0.0, c=1.0, dyn_early_term=False, dyn_early_term_cutoff=0.8999999761581421, early_term=False, early_term_turns=True, e_greedy=False, e_g_subset=20, roulette=False, epsilon=0.05000000074505806, node_priors=False, debug=False> -> mv.: (2, 1).\n",
      "  0  1  2\n",
      "0 \u001b[97m \u001b[0m  \u001b[97m \u001b[0m  \u001b[1m\u001b[31mO\u001b[0m\n",
      "1 \u001b[1m\u001b[31mO\u001b[0m  \u001b[1m\u001b[32mX\u001b[0m  \u001b[1m\u001b[31mO\u001b[0m\n",
      "2 \u001b[1m\u001b[32mX\u001b[0m  \u001b[1m\u001b[32mX\u001b[0m  \u001b[1m\u001b[32mX\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the best action for the current player\n",
    "action, _ = current_player.best_action(game)\n",
    "\n",
    "# Apply the action to get the new game state\n",
    "game = game.apply_action(action)\n",
    "\n",
    "# Call the callback function if any\n",
    "if callback is not None:\n",
    "    callback(current_player, action, game, 0)\n",
    "\n",
    "# Switch the current player\n",
    "current_player = player2 if game.player == 2 else player1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_n_in_a_row',\n",
    "                     max_player=1, ai_params={\"max_time\": 16, \"debug\": True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_n_in_a_row',\n",
    "                     max_player=2, ai_params={\"max_time\": 6, \"debug\": True})\n",
    "# An n-in-a-row game\n",
    "run_game(game_key='tictactoe', game_params={\"board_size\" : 9, \"row_length\": 6}, \n",
    "         p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_breakthrough_lorenz', max_player=1,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_tt\": False, \"use_null_moves\":True, \"use_quiescence\":True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_breakthrough_lorenz', max_player=2,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_null_moves\":False})\n",
    "\n",
    "run_game(game_key='breakthrough', game_params={}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_kalah_enhanced', max_player=1,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_tt\": False, \"use_quiescence\": True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_kalah_enhanced', max_player=2,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "``\n",
    "run_game(game_key='kalah', game_params={}, p1_params=p1_params, p2_params=p2_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_amazons', max_player=1,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True, \"use_tt\": False})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_amazons',max_player=2,\n",
    "                     ai_params={\"max_time\": 10, \"debug\": True})\n",
    "\n",
    "run_game(game_key='amazons', game_params={\"board_size\": 8}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_games import run_game, AIParams\n",
    "\n",
    "p1_params = AIParams(ai_key='alphabeta', eval_key='evaluate_blokus', max_player=1,\n",
    "                     ai_params={\"max_time\": 15, \"debug\": True, \"use_null_moves\": True})\n",
    "p2_params = AIParams(ai_key='alphabeta', eval_key='evaluate_blokus',max_player=2,\n",
    "                     ai_params={\"max_time\": 15, \"debug\": True})\n",
    "\n",
    "run_game(game_key='blokus', game_params={}, p1_params=p1_params, p2_params=p2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import unittest\n",
    "\n",
    "from games.gamestate import GameState\n",
    "\n",
    "# TODO Hier was je gebleven, je moet de random move generation testen\n",
    "def test_random_action_generation(state: GameState):\n",
    "    # Generate a large number of actions\n",
    "    num_trials = 100000\n",
    "    generated_actions = [state.get_random_action() for _ in range(num_trials)]\n",
    "\n",
    "    # Check coverage\n",
    "    unique_generated_actions = set(generated_actions)\n",
    "    all_possible_actions = state.get_legal_actions()\n",
    "    # TODO This should be a soft check, but it's not\n",
    "    assert unique_generated_actions == all_possible_actions, \"Not all actions were generated\"\n",
    "\n",
    "    # Check uniformity\n",
    "    action_counts = collections.Counter(generated_actions)\n",
    "    min_count = min(action_counts.values())\n",
    "    max_count = max(action_counts.values())\n",
    "    return max_count - min_count < num_trials * 0.05 #\"Generated actions are uniformly distributed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_legal_actions(game):\n",
    "    actions_from_get = game.get_legal_actions()\n",
    "    actions_from_yield = list(game.yield_legal_actions())\n",
    "\n",
    "    # Check if the generated moves from both functions are unique\n",
    "    is_unique_get = len(actions_from_get) == len(set(actions_from_get))\n",
    "    is_unique_yield = len(actions_from_yield) == len(set(actions_from_yield))\n",
    "\n",
    "    # Check if the two sets of actions are equal\n",
    "    are_equal = set(actions_from_get) == set(actions_from_yield)\n",
    "\n",
    "    return are_equal and is_unique_get and is_unique_yield\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
